"""
Speech to Text Module - Python 3.13 Compatible
No dependency on deprecated aifc module
"""

import os
import logging
import numpy as np
import io
import wave
from typing import Optional
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

# Check for available speech recognition options
WHISPER_AVAILABLE = False
try:
    import whisper
    WHISPER_AVAILABLE = True
    logger.info("âœ… Whisper available for speech recognition")
except ImportError:
    logger.warning("Whisper not available, will use mock recognition")

class SpeechToText:
    """Speech to text conversion for Python 3.13+"""
    
    def __init__(self):
        """Initialize STT with Python 3.13 compatible provider"""
        self.language = os.getenv('STT_LANGUAGE', 'en')
        
        if WHISPER_AVAILABLE:
            self.provider = 'whisper'
            try:
                # Load smallest model for speed
                logger.info("Loading Whisper model (first time may take a few minutes)...")
                self.whisper_model = whisper.load_model("tiny")
                logger.info("âœ… Whisper model loaded successfully")
            except Exception as e:
                logger.error(f"Failed to load Whisper model: {e}")
                self.provider = 'mock'
        else:
            self.provider = 'mock'
            logger.warning("Using mock STT - install whisper with: pip install openai-whisper")
    
    async def transcribe(self, audio_data: np.ndarray) -> Optional[str]:
        """Convert audio to text"""
        if not audio_data.size:
            return None
            
        if self.provider == 'whisper' and WHISPER_AVAILABLE:
            try:
                # Ensure audio is float32 for Whisper
                if audio_data.dtype != np.float32:
                    audio_data = audio_data.astype(np.float32)
                    # Normalize if it was int16
                    if audio_data.max() > 1.0:
                        audio_data = audio_data / 32768.0
                
                # Transcribe
                result = self.whisper_model.transcribe(
                    audio_data,
                    language=self.language,
                    fp16=False  # Disable for CPU compatibility
                )
                
                text = result.get('text', '').strip()
                if text:
                    logger.info(f"ðŸ“ Transcribed: {text}")
                    return text
                    
            except Exception as e:
                logger.error(f"Whisper transcription error: {e}")
                
        # Fallback to mock
        return self._mock_transcribe(len(audio_data))
    
    def _mock_transcribe(self, audio_length: int) -> str:
        """Mock transcription for testing without real STT"""
        if audio_length < 1000:
            return None
        elif audio_length < 10000:
            return "Hello"
        elif audio_length < 50000:
            return "How can I help you?"
        else:
            return "This is a test transcription"
